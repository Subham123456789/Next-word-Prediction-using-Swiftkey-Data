{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1():\n",
    "    from transformers import OpenAIGPTTokenizer,OpenAIGPTLMHeadModel,\\\n",
    "    TextDataset,TrainingArguments,Trainer,pipeline,DataCollatorForLanguageModeling\n",
    "    import re \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    \n",
    "    tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")\n",
    "    #model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n",
    "    generator = pipeline('text-generation', tokenizer='openai-gpt', model='gpt_model') \n",
    "    while(True):\n",
    "        text = input('Enter the text or press q to exit : ')\n",
    "        if text == 'q' or text == 'Q':\n",
    "            print('Exiting .')\n",
    "            break\n",
    "        length= len(tokenizer.encode(text, return_tensors='pt')[0])\n",
    "        max_length = length+1\n",
    "    \n",
    "        print('Next Word: ')\n",
    "        print(generator(text , max_length=max_length)[0]['generated_text'].split(' ')[-1])\n",
    "        print(generator(text , max_length=max_length , num_beams = 5)[0]['generated_text'].split(' ')[-1])\n",
    "        print(generator(text , max_length=max_length , do_sample=True,temperature = 0.7)[0]['generated_text'].split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text or press q to exit : what a beautiful \n",
      "Next Word: \n",
      "piece\n",
      "woman\n",
      "thing\n",
      "Enter the text or press q to exit : even if I am \n",
      "Next Word: \n",
      "to\n",
      "in\n",
      "a\n",
      "Enter the text or press q to exit : let us think this \n",
      "Next Word: \n",
      "is\n",
      "is\n",
      "is\n",
      "Enter the text or press q to exit : Nowadays \n",
      "Next Word: \n",
      "to\n",
      "the\n",
      "of\n",
      "Enter the text or press q to exit : Sports are \n",
      "Next Word: \n",
      "a\n",
      "the\n",
      "the\n",
      "Enter the text or press q to exit : Great sense of \n",
      "Next Word: \n",
      "humor\n",
      "humor\n",
      "humor\n",
      "Enter the text or press q to exit : I love to \n",
      "Next Word: \n",
      "work\n",
      "be\n",
      "be\n",
      "Enter the text or press q to exit : Smartphones are \n",
      "Next Word: \n",
      "actually\n",
      "used\n",
      "being\n",
      "Enter the text or press q to exit : The food was \n",
      "Next Word: \n",
      "good\n",
      "good\n",
      "good\n",
      "Enter the text or press q to exit : Exams are to be \n",
      "Next Word: \n",
      "expected\n",
      "a\n",
      "considered\n",
      "Enter the text or press q to exit : q\n",
      "Exiting .\n"
     ]
    }
   ],
   "source": [
    "final_fun_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2():\n",
    "    from transformers import OpenAIGPTTokenizer,OpenAIGPTLMHeadModel,\\\n",
    "    TextDataset,TrainingArguments,Trainer,pipeline,DataCollatorForLanguageModeling\n",
    "    import re \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import numpy as np\n",
    "    \n",
    "    tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")\n",
    "    model = OpenAIGPTLMHeadModel.from_pretrained('gpt_model')\n",
    "    while(True):\n",
    "        text = input('Enter the text or press q to exit : ')\n",
    "        if text == 'q' or text == 'Q':\n",
    "            print('Exiting .')\n",
    "            break\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "        length= len(tokenizer.encode(text, return_tensors='pt')[0])\n",
    "        max_length = length+1\n",
    "    \n",
    "        # Generating the sequence and output scores\n",
    "        generation_output = model.generate(input_ids=inputs, max_length=max_length,return_dict_in_generate=True,\\\n",
    "                                           output_scores=True,  do_sample=True, skip_special_tokens=True)\n",
    "        token_id = generation_output['sequences'][0][-1]\n",
    "        # Applying softmax to the output score\n",
    "        scores = np.exp(generation_output.scores[0][0].tolist())/np.exp(generation_output.scores[0][0].tolist()).sum()\n",
    "        output_score = scores[token_id]\n",
    "        print('Next Word: ',tokenizer.decode(token_id),'| Output_Score : ',output_score )\n",
    "        \n",
    "        generation_output = model.generate(input_ids=inputs, max_length=max_length,return_dict_in_generate=True,\\\n",
    "                                           output_scores=True,num_beams=5,skip_special_tokens=True)\n",
    "        token_id = generation_output['sequences'][0][-1]\n",
    "        scores = np.exp(generation_output.scores[0][0].tolist())/np.exp(generation_output.scores[0][0].tolist()).sum()\n",
    "        output_score = scores[token_id]\n",
    "        print('Next Word: ',tokenizer.decode(token_id),'|  Output_Score : ',output_score)\n",
    "        \n",
    "        \n",
    "        generation_output = model.generate(input_ids=inputs, max_length=max_length, return_dict_in_generate=True, \\\n",
    "                                           output_scores=True , do_sample=True , temperature= 0.7,skip_special_tokens=True)\n",
    "        token_id = generation_output['sequences'][0][-1]\n",
    "        scores = np.exp(generation_output.scores[0][0].tolist())/np.exp(generation_output.scores[0][0].tolist()).sum()\n",
    "        output_score = scores[token_id]\n",
    "        print('Next Word: ',tokenizer.decode(token_id),'|  Output_Score : ',output_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text or press q to exit : The day is \n",
      "Next Word:  over | Output_Score :  0.04150524540613543\n",
      "Next Word:  just |  Output_Score :  0.0937788154828969\n",
      "Next Word:  pretty |  Output_Score :  0.010252802775124593\n",
      "Enter the text or press q to exit : she is just \n",
      "Next Word:  being | Output_Score :  0.01608901018717687\n",
      "Next Word:  a |  Output_Score :  0.30173295575785614\n",
      "Next Word:  a |  Output_Score :  0.5534450852196151\n",
      "Enter the text or press q to exit : Honesty is \n",
      "Next Word:  that | Output_Score :  0.20330489762549572\n",
      "Next Word:  that |  Output_Score :  0.1291139151273034\n",
      "Next Word:  that |  Output_Score :  0.327967984756954\n",
      "Enter the text or press q to exit : why dont u \n",
      "Next Word:  have | Output_Score :  0.07494001518408915\n",
      "Next Word:  think |  Output_Score :  0.1315875954548692\n",
      "Next Word:  need |  Output_Score :  0.06539941417951795\n",
      "Enter the text or press q to exit : q\n",
      "Exiting .\n"
     ]
    }
   ],
   "source": [
    "final_fun_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
